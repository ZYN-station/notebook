{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Transformer模型测试任务--copy任务\n",
    "### 实现copy任务的四部曲：\n",
    "1. 构建数据集生成器\n",
    "2. 获得Transformer模型及其优化器和损失函数\n",
    "3. 运行模型进行训练和评估\n",
    "4. 使用模型进行贪婪解码\n",
    "\n",
    "> copy任务介绍：\n",
    "> - 任务描述：针对数字序列进行学习，学习的最终目标是使输出与输入序列相同。如输入[1,5,8,9,3],输出也是[1,5,8,9,3]\n",
    "> - 任务意义：copy任务在模型基础测试中具有重要意义，因为copy操作对于模型来讲是一条明显的规律，因此模型能否在短时间内，小数据集中学会它，可以帮助我们断定模型所有过程是否正常，是否已具备基本学习能力。"
   ],
   "id": "841abf1b4c95dc5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T12:46:04.807814Z",
     "start_time": "2025-02-06T12:45:59.343583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"构建数据集生成器\"\"\"\n",
    "from pyitcast.transformer_utils import Batch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def data_generator(V, batch_size, num_batch):\n",
    "    for i in range(num_batch):\n",
    "        data = torch.from_numpy(np.random.randint(1,V,size=(batch_size,10)))\n",
    "        # 第0位设置为1作为起始标志\n",
    "        data[:,0] = 1\n",
    "        source = Variable(data,requires_grad = False)\n",
    "        target = Variable(data,requires_grad = False)\n",
    "        \n",
    "        #使用Batch对source和target进行对应批次的掩码张量生成\n",
    "        yield Batch(source,target)"
   ],
   "id": "4713a0a25fc7ed85",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T12:46:04.822212Z",
     "start_time": "2025-02-06T12:46:04.810833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 输入参数与调用\n",
    "V = 11\n",
    "batch_size = 20\n",
    "num_batch = 30\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    res = data_generator(V,batch_size,num_batch)\n",
    "    print(res)"
   ],
   "id": "49e12618dd0c0597",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object data_generator at 0x00000194516B0B80>\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ab14422d378db7fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T12:46:08.311818Z",
     "start_time": "2025-02-06T12:46:04.824232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导入优化器工具包get_std_opt, 该工具用于获得标准的针对Transformer模型的优化器 \n",
    "# 该标准优化器基于Adam优化器, 使其对序列到序列的任务更有效.\n",
    "from  TransformerModel import make_mode\n",
    "from pyitcast.transformer_utils import get_std_opt\n",
    "\n",
    "# 导入标签平滑工具包, 该工具用于标签平滑, 标签平滑的作用就是小幅度的改变原有标签值的值域\n",
    "# 因为在理论上即使是人工的标注数据也可能并非完全正确, 会受到一些外界因素的影响而产生一些微小的偏差\n",
    "# 因此使用标签平滑来弥补这种偏差, 减少模型对某一条规律的绝对认知, 以防止过拟合. 通过下面示例了解更多.\n",
    "from pyitcast.transformer_utils import LabelSmoothing\n",
    "\n",
    "# 导入损失计算工具包, 该工具能够使用标签平滑后的结果进行损失的计算, \n",
    "# 损失的计算方法可以认为是交叉熵损失函数.\n",
    "from pyitcast.transformer_utils import SimpleLossCompute\n",
    "\n",
    "# 使用make_model获得model\n",
    "model = make_mode(V,V,N=2)\n",
    "\n",
    "# 使用get_std_opt获得模型优化器\n",
    "model_optimizer = get_std_opt(model)\n",
    "\n",
    "# 使用LabelSmoothing获得标签平滑对象\n",
    "criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "\n",
    "# 使用SimpleLossCompute获得利用标签平滑结果的损失计算方法\n",
    "loss = SimpleLossCompute(model, criterion, model_optimizer)\n"
   ],
   "id": "2155b38d6f06bea8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Edith_ZYN\\MLResource\\Transformer\\TransformerModel.py:229: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n",
      "  nn.init.xavier_uniform(p)\n",
      "D:\\Program Files\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T12:49:07.115165Z",
     "start_time": "2025-02-06T12:49:06.961020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyitcast.transformer_utils import LabelSmoothing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# 使用LabelSmoothing实例化一个crit对象.\n",
    "# 第一个参数size代表目标数据的词汇总数, 也是模型最后一层得到张量的最后一维大小\n",
    "# 这里是5说明目标词汇总数是5个. 第二个参数padding_idx表示要将那些tensor中的数字\n",
    "# 替换成0, 一般padding_idx=0表示不进行替换. 第三个参数smoothing, 表示标签的平滑程度\n",
    "# 如原来标签的表示值为1, 则平滑后它的值域变为[1-smoothing, 1+smoothing].\n",
    "crit = LabelSmoothing(size=5, padding_idx=0, smoothing=0.5)\n",
    "\n",
    "# 假定一个任意的模型最后输出预测结果和真实结果\n",
    "predict = Variable(torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0],\n",
    "                             [0, 0.2, 0.7, 0.1, 0], \n",
    "                             [0, 0.2, 0.7, 0.1, 0]]))\n",
    "\n",
    "# 标签的表示值是0，1，2\n",
    "target = Variable(torch.LongTensor([2, 1, 0]))\n",
    "\n",
    "# 将predict, target传入到对象中\n",
    "crit(predict, target)\n",
    "\n",
    "# 绘制标签平滑图像\n",
    "plt.imshow(crit.true_dist)\n",
    "plt.show()"
   ],
   "id": "402e17497bb03711",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T12:49:11.705019Z",
     "start_time": "2025-02-06T12:49:11.698333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyitcast.transformer_utils import run_epoch\n",
    "\n",
    "def run(model, loss, epochs=10):\n",
    "    \"\"\"模型训练函数, 共有三个参数, model代表将要进行训练的模型\n",
    "       loss代表使用的损失计算方法, epochs代表模型训练的轮数\"\"\"\n",
    "\n",
    "    # 遍历轮数\n",
    "    for epoch in range(epochs):\n",
    "        # 模型使用训练模式, 所有参数将被更新\n",
    "        model.train()\n",
    "        # 训练时, batch_size是20\n",
    "        run_epoch(data_generator(V, 8, 20), model, loss)\n",
    "\n",
    "        # 模型使用评估模式, 参数将不会变化 \n",
    "        model.eval()\n",
    "        # 评估时, batch_size是5\n",
    "        run_epoch(data_generator(V, 8, 5), model, loss)"
   ],
   "id": "dd1e0586519c721f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T12:50:04.821153Z",
     "start_time": "2025-02-06T12:50:03.532495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyitcast.transformer_utils import greedy_decode \n",
    "\n",
    "\n",
    "def run(model, loss, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        run_epoch(data_generator(V, 8, 20), model, loss)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        run_epoch(data_generator(V, 8, 5), model, loss)\n",
    "\n",
    "    # 模型进入测试模式\n",
    "    model.eval()\n",
    "\n",
    "    # 假定的输入张量\n",
    "    source = Variable(torch.LongTensor([[1,3,2,5,4,6,7,8,9,10]]))\n",
    "\n",
    "    # 定义源数据掩码张量, 因为元素都是1, 在我们这里1代表不遮掩\n",
    "    # 因此相当于对源数据没有任何遮掩.\n",
    "    source_mask = Variable(torch.ones(1, 1, 10))\n",
    "\n",
    "    # 最后将model, src, src_mask, 解码的最大长度限制max_len, 默认为10\n",
    "    # 以及起始标志数字, 默认为1, 我们这里使用的也是1\n",
    "    result = greedy_decode(model, source, source_mask, max_len=10, start_symbol=1)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run(model, loss)\n"
   ],
   "id": "6122e97d1f41b80e",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (11) must match the size of tensor b (512) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 31\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28mprint\u001B[39m(result)\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m---> 31\u001B[0m     run(model, loss)\n",
      "Cell \u001B[1;32mIn[12], line 8\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(model, loss, epochs)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m      6\u001B[0m     model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m----> 8\u001B[0m     run_epoch(data_generator(V, \u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m20\u001B[39m), model, loss)\n\u001B[0;32m     10\u001B[0m     model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m     12\u001B[0m     run_epoch(data_generator(V, \u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m5\u001B[39m), model, loss)\n",
      "File \u001B[1;32mD:\\Program Files\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pyitcast\\transformer_utils.py:46\u001B[0m, in \u001B[0;36mrun_epoch\u001B[1;34m(data_iter, model, loss_compute)\u001B[0m\n\u001B[0;32m     44\u001B[0m tokens \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(data_iter):\n\u001B[1;32m---> 46\u001B[0m     out \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mforward(batch\u001B[38;5;241m.\u001B[39msrc, batch\u001B[38;5;241m.\u001B[39mtrg, \n\u001B[0;32m     47\u001B[0m                         batch\u001B[38;5;241m.\u001B[39msrc_mask, batch\u001B[38;5;241m.\u001B[39mtrg_mask)\n\u001B[0;32m     48\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_compute(out, batch\u001B[38;5;241m.\u001B[39mtrg_y, batch\u001B[38;5;241m.\u001B[39mntokens)\n\u001B[0;32m     49\u001B[0m     total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n",
      "File \u001B[1;32mD:\\Edith_ZYN\\MLResource\\Transformer\\TransformerModel.py:196\u001B[0m, in \u001B[0;36mEncoderDecoder.forward\u001B[1;34m(self, source, target, source_mask, target_mask)\u001B[0m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m,source,target,source_mask,target_mask):\n\u001B[1;32m--> 196\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode(source,source_mask),source_mask,target,target_mask)\n",
      "File \u001B[1;32mD:\\Edith_ZYN\\MLResource\\Transformer\\TransformerModel.py:198\u001B[0m, in \u001B[0;36mEncoderDecoder.encode\u001B[1;34m(self, source, source_mask)\u001B[0m\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mencode\u001B[39m(\u001B[38;5;28mself\u001B[39m,source,source_mask):\n\u001B[1;32m--> 198\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msrc_embed(source),source_mask)\n",
      "File \u001B[1;32mD:\\Program Files\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Program Files\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\Program Files\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    248\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 250\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m    251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mD:\\Program Files\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Program Files\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\Edith_ZYN\\MLResource\\Transformer\\TransformerModel.py:31\u001B[0m, in \u001B[0;36mPositionEncoding.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m,x):\n\u001B[1;32m---> 31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(x\u001B[38;5;241m+\u001B[39mVariable(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpe[:,x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m)],requires_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (11) must match the size of tensor b (512) at non-singleton dimension 2"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b6efebf9a9cd987c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
